{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3085ec43-34bb-4afb-9515-517e0489db3e",
   "metadata": {
    "id": "3085ec43-34bb-4afb-9515-517e0489db3e"
   },
   "source": [
    "## Ансамбли и полносвязные нейронные сети\n",
    "В этом ноутбуке вам нужно обучить модели на датасете классификации из предыдущего ноутбука и сравнить результаты. Вам будет предоставлен baseline, на основе которого вы будете доделывать предсказывающие модели. Оценка лабы будет зависеть от ROC-AUC на тестовых данных по следующим критериям:\n",
    "\\\n",
    "AUC - на тестовых данных\n",
    "- $AUC \\leq 0.76$ - 0 баллов\n",
    "- $0.76 < AUC \\leq 0.77$ - 2 балла\n",
    "- $0.77 < AUC \\leq 0.78$ - 4 балла\n",
    "- $0.78 < AUC \\leq 0.79$ - 6 баллов\n",
    "- $0.79 < AUC \\leq 0.80$ - 8 баллов\n",
    "- $AUC > 0.80$ - 10 баллов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bIhnqzqamfTf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bIhnqzqamfTf",
    "outputId": "a4478f43-2c20-4947-a9a3-a651ac01fd7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: optuna in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.0.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from optuna) (1.13.3)\n",
      "Requirement already satisfied: colorlog in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from optuna) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from optuna) (2.0.36)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\dan4i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\dan4i\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec07e3a2-480a-4350-868e-02679ff2aada",
   "metadata": {
    "id": "ec07e3a2-480a-4350-868e-02679ff2aada",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, roc_curve, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563ad31b-5c83-4366-819a-34dad4edecdc",
   "metadata": {
    "collapsed": true,
    "id": "563ad31b-5c83-4366-819a-34dad4edecdc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('german.csv', sep=';')\n",
    "data = data.drop('Foreign_Worker', axis=1)\n",
    "\n",
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "missing_values_count = X.isnull().sum()\n",
    "X_cleaned = X.dropna() if missing_values_count.sum() < len(X) * 0.05 else X.fillna(X.median())\n",
    "\n",
    "Q1 = X_cleaned.quantile(0.25)\n",
    "Q3 = X_cleaned.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "mask = ~((X_cleaned < (Q1 - 1.5 * IQR)) | (X_cleaned > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "X_no_outliers = X_cleaned[mask]\n",
    "y_no_outliers = y[mask]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_no_outliers, y_no_outliers, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f93737ec-e5eb-4d72-8beb-5dba4d4c581f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "collapsed": true,
    "id": "f93737ec-e5eb-4d72-8beb-5dba4d4c581f",
    "outputId": "cfc4d5e5-d50b-43da-9f2d-0d7c06d68a31",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, bins=2, edgecolor='k')\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel('Class (0: Non-Creditworthy, 1: Creditworthy)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Classes in Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rKH0qkZ1xwhb",
   "metadata": {
    "id": "rKH0qkZ1xwhb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dan4i\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#масштабируем данные\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eNNbmNuLlwKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "eNNbmNuLlwKf",
    "outputId": "8004741d-6d75-4782-b368-ae8d38502aa9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-31 20:24:48,031] A new study created in memory with name: no-name-c6a5c0bf-12a0-4d2c-8af2-637528fe2e30\n",
      "[I 2024-10-31 20:24:48,083] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 132, 'learning_rate': 0.008871806794612047, 'max_depth': 234, 'min_samples_split': 153, 'min_samples_leaf': 91}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-10-31 20:24:48,093] Trial 1 finished with value: 0.5 and parameters: {'n_estimators': 17, 'learning_rate': 3.442400592538253, 'max_depth': 217, 'min_samples_split': 191, 'min_samples_leaf': 38}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-10-31 20:24:48,130] Trial 2 finished with value: 0.7412698412698412 and parameters: {'n_estimators': 93, 'learning_rate': 0.17613782447216425, 'max_depth': 320, 'min_samples_split': 30, 'min_samples_leaf': 68}. Best is trial 2 with value: 0.7412698412698412.\n",
      "[I 2024-10-31 20:24:48,149] Trial 3 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 42, 'learning_rate': 0.13758500769538162, 'max_depth': 421, 'min_samples_split': 188, 'min_samples_leaf': 37}. Best is trial 2 with value: 0.7412698412698412.\n",
      "[I 2024-10-31 20:24:48,221] Trial 4 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 155, 'learning_rate': 0.03626358125557264, 'max_depth': 447, 'min_samples_split': 195, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7412698412698412.\n",
      "[I 2024-10-31 20:24:48,243] Trial 5 finished with value: 0.5 and parameters: {'n_estimators': 35, 'learning_rate': 0.0004943214020599621, 'max_depth': 209, 'min_samples_split': 94, 'min_samples_leaf': 39}. Best is trial 2 with value: 0.7412698412698412.\n",
      "[I 2024-10-31 20:24:48,325] Trial 6 finished with value: 0.5 and parameters: {'n_estimators': 127, 'learning_rate': 0.0005297110148565206, 'max_depth': 194, 'min_samples_split': 45, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.7412698412698412.\n",
      "[I 2024-10-31 20:24:48,398] Trial 7 finished with value: 0.680952380952381 and parameters: {'n_estimators': 198, 'learning_rate': 0.2300077689734747, 'max_depth': 313, 'min_samples_split': 194, 'min_samples_leaf': 69}. Best is trial 2 with value: 0.7412698412698412.\n",
      "[I 2024-10-31 20:24:48,464] Trial 8 finished with value: 0.7412698412698412 and parameters: {'n_estimators': 152, 'learning_rate': 0.40233416777560826, 'max_depth': 43, 'min_samples_split': 149, 'min_samples_leaf': 11}. Best is trial 2 with value: 0.7412698412698412.\n",
      "[I 2024-10-31 20:24:48,492] Trial 9 finished with value: 0.5 and parameters: {'n_estimators': 67, 'learning_rate': 5.69267266338877, 'max_depth': 196, 'min_samples_split': 122, 'min_samples_leaf': 72}. Best is trial 2 with value: 0.7412698412698412.\n",
      "[I 2024-10-31 20:24:48,537] Trial 10 finished with value: 0.5 and parameters: {'n_estimators': 79, 'learning_rate': 0.006777508641924636, 'max_depth': 341, 'min_samples_split': 3, 'min_samples_leaf': 96}. Best is trial 2 with value: 0.7412698412698412.\n",
      "[I 2024-10-31 20:24:48,624] Trial 11 finished with value: 0.6698412698412698 and parameters: {'n_estimators': 178, 'learning_rate': 0.6540972853319565, 'max_depth': 21, 'min_samples_split': 74, 'min_samples_leaf': 62}. Best is trial 2 with value: 0.7412698412698412.\n",
      "[I 2024-10-31 20:24:48,685] Trial 12 finished with value: 0.8238095238095238 and parameters: {'n_estimators': 108, 'learning_rate': 0.6906790306647492, 'max_depth': 25, 'min_samples_split': 138, 'min_samples_leaf': 20}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:48,762] Trial 13 finished with value: 0.5380952380952381 and parameters: {'n_estimators': 102, 'learning_rate': 1.5927927472144268, 'max_depth': 89, 'min_samples_split': 20, 'min_samples_leaf': 24}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:48,820] Trial 14 finished with value: 0.680952380952381 and parameters: {'n_estimators': 98, 'learning_rate': 0.04149538942627344, 'max_depth': 333, 'min_samples_split': 59, 'min_samples_leaf': 53}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:48,878] Trial 15 finished with value: 0.5 and parameters: {'n_estimators': 115, 'learning_rate': 0.0049866383682622435, 'max_depth': 112, 'min_samples_split': 111, 'min_samples_leaf': 83}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:48,925] Trial 16 finished with value: 0.7523809523809523 and parameters: {'n_estimators': 74, 'learning_rate': 1.0262489425241292, 'max_depth': 384, 'min_samples_split': 143, 'min_samples_leaf': 23}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:48,961] Trial 17 finished with value: 0.7412698412698412 and parameters: {'n_estimators': 50, 'learning_rate': 0.9799437623693111, 'max_depth': 496, 'min_samples_split': 148, 'min_samples_leaf': 23}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,005] Trial 18 finished with value: 0.16666666666666666 and parameters: {'n_estimators': 67, 'learning_rate': 8.12844249348335, 'max_depth': 139, 'min_samples_split': 127, 'min_samples_leaf': 23}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,025] Trial 19 finished with value: 0.6968253968253968 and parameters: {'n_estimators': 11, 'learning_rate': 2.058771742816895, 'max_depth': 385, 'min_samples_split': 167, 'min_samples_leaf': 17}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,076] Trial 20 finished with value: 0.8238095238095238 and parameters: {'n_estimators': 77, 'learning_rate': 0.07453422368272902, 'max_depth': 273, 'min_samples_split': 91, 'min_samples_leaf': 45}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,130] Trial 21 finished with value: 0.692063492063492 and parameters: {'n_estimators': 75, 'learning_rate': 0.08499939337735435, 'max_depth': 274, 'min_samples_split': 89, 'min_samples_leaf': 33}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,168] Trial 22 finished with value: 0.7634920634920634 and parameters: {'n_estimators': 55, 'learning_rate': 0.3748121279937699, 'max_depth': 266, 'min_samples_split': 132, 'min_samples_leaf': 50}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,210] Trial 23 finished with value: 0.5 and parameters: {'n_estimators': 56, 'learning_rate': 0.01672141866274632, 'max_depth': 280, 'min_samples_split': 111, 'min_samples_leaf': 50}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,239] Trial 24 finished with value: 0.5 and parameters: {'n_estimators': 29, 'learning_rate': 0.0015514065851947021, 'max_depth': 161, 'min_samples_split': 82, 'min_samples_leaf': 49}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,289] Trial 25 finished with value: 0.6698412698412698 and parameters: {'n_estimators': 86, 'learning_rate': 0.07942594179790778, 'max_depth': 259, 'min_samples_split': 130, 'min_samples_leaf': 56}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,308] Trial 26 finished with value: 0.5 and parameters: {'n_estimators': 1, 'learning_rate': 0.3958202357226886, 'max_depth': 80, 'min_samples_split': 165, 'min_samples_leaf': 46}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,380] Trial 27 finished with value: 0.5 and parameters: {'n_estimators': 109, 'learning_rate': 0.00014969899192313822, 'max_depth': 153, 'min_samples_split': 115, 'min_samples_leaf': 33}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,445] Trial 28 finished with value: 0.680952380952381 and parameters: {'n_estimators': 119, 'learning_rate': 0.35930181475161344, 'max_depth': 299, 'min_samples_split': 102, 'min_samples_leaf': 61}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,514] Trial 29 finished with value: 0.680952380952381 and parameters: {'n_estimators': 144, 'learning_rate': 0.06325068128397993, 'max_depth': 242, 'min_samples_split': 168, 'min_samples_leaf': 77}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,553] Trial 30 finished with value: 0.5 and parameters: {'n_estimators': 56, 'learning_rate': 0.022316305036233896, 'max_depth': 359, 'min_samples_split': 136, 'min_samples_leaf': 44}. Best is trial 12 with value: 0.8238095238095238.\n",
      "[I 2024-10-31 20:24:49,605] Trial 31 finished with value: 0.8507936507936509 and parameters: {'n_estimators': 86, 'learning_rate': 1.2058873979701377, 'max_depth': 411, 'min_samples_split': 140, 'min_samples_leaf': 30}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:49,670] Trial 32 finished with value: 0.5 and parameters: {'n_estimators': 94, 'learning_rate': 3.5243835174395337, 'max_depth': 444, 'min_samples_split': 69, 'min_samples_leaf': 31}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:49,742] Trial 33 finished with value: 0.8333333333333333 and parameters: {'n_estimators': 137, 'learning_rate': 1.9319682066314985, 'max_depth': 498, 'min_samples_split': 161, 'min_samples_leaf': 42}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:49,810] Trial 34 finished with value: 0.3031746031746032 and parameters: {'n_estimators': 136, 'learning_rate': 3.034589178276516, 'max_depth': 484, 'min_samples_split': 176, 'min_samples_leaf': 40}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:49,876] Trial 35 finished with value: 0.7523809523809523 and parameters: {'n_estimators': 128, 'learning_rate': 0.17371373426668374, 'max_depth': 466, 'min_samples_split': 179, 'min_samples_leaf': 29}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:49,958] Trial 36 finished with value: 0.8126984126984127 and parameters: {'n_estimators': 165, 'learning_rate': 0.8988420029920793, 'max_depth': 401, 'min_samples_split': 156, 'min_samples_leaf': 43}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,037] Trial 37 finished with value: 0.526984126984127 and parameters: {'n_estimators': 107, 'learning_rate': 1.6847426480911054, 'max_depth': 427, 'min_samples_split': 157, 'min_samples_leaf': 1}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,096] Trial 38 finished with value: 0.8333333333333333 and parameters: {'n_estimators': 86, 'learning_rate': 5.339693751124062, 'max_depth': 464, 'min_samples_split': 96, 'min_samples_leaf': 15}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,170] Trial 39 finished with value: 0.16666666666666666 and parameters: {'n_estimators': 138, 'learning_rate': 8.11989813189838, 'max_depth': 464, 'min_samples_split': 140, 'min_samples_leaf': 16}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,241] Trial 40 finished with value: 0.719047619047619 and parameters: {'n_estimators': 121, 'learning_rate': 4.441579922397719, 'max_depth': 418, 'min_samples_split': 102, 'min_samples_leaf': 9}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,303] Trial 41 finished with value: 0.7063492063492064 and parameters: {'n_estimators': 87, 'learning_rate': 1.966356678792434, 'max_depth': 486, 'min_samples_split': 95, 'min_samples_leaf': 16}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,361] Trial 42 finished with value: 0.8126984126984127 and parameters: {'n_estimators': 87, 'learning_rate': 0.7063906613183586, 'max_depth': 458, 'min_samples_split': 120, 'min_samples_leaf': 38}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,419] Trial 43 finished with value: 0.23333333333333334 and parameters: {'n_estimators': 68, 'learning_rate': 2.9319418591549784, 'max_depth': 363, 'min_samples_split': 55, 'min_samples_leaf': 27}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,493] Trial 44 finished with value: 0.7634920634920634 and parameters: {'n_estimators': 112, 'learning_rate': 0.18630381440000648, 'max_depth': 434, 'min_samples_split': 84, 'min_samples_leaf': 36}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,551] Trial 45 finished with value: 0.3031746031746032 and parameters: {'n_estimators': 97, 'learning_rate': 9.740444046057508, 'max_depth': 221, 'min_samples_split': 181, 'min_samples_leaf': 12}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,656] Trial 46 finished with value: 0.6666666666666666 and parameters: {'n_estimators': 155, 'learning_rate': 5.391674773986642, 'max_depth': 404, 'min_samples_split': 73, 'min_samples_leaf': 5}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,690] Trial 47 finished with value: 0.7523809523809523 and parameters: {'n_estimators': 38, 'learning_rate': 1.3227743321603584, 'max_depth': 498, 'min_samples_split': 200, 'min_samples_leaf': 17}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,743] Trial 48 finished with value: 0.7634920634920634 and parameters: {'n_estimators': 82, 'learning_rate': 0.5512313706711145, 'max_depth': 477, 'min_samples_split': 107, 'min_samples_leaf': 57}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,807] Trial 49 finished with value: 0.7523809523809523 and parameters: {'n_estimators': 102, 'learning_rate': 0.26672842800981234, 'max_depth': 52, 'min_samples_split': 122, 'min_samples_leaf': 28}. Best is trial 31 with value: 0.8507936507936509.\n",
      "[I 2024-10-31 20:24:50,808] A new study created in memory with name: no-name-abd04064-2af0-478a-8575-73ce531868ce\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC-AUC for GradientBoostingClassifier:  0.8507936507936509\n",
      "Best hyperparameters for GradientBoostingClassifier:  {'n_estimators': 86, 'learning_rate': 1.2058873979701377, 'max_depth': 411, 'min_samples_split': 140, 'min_samples_leaf': 30}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dan4i\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (129) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-10-31 20:24:51,069] Trial 0 finished with value: 0.7031746031746031 and parameters: {'hidden_layer_sizes ': 769, 'max_iter': 129}. Best is trial 0 with value: 0.7031746031746031.\n",
      "[I 2024-10-31 20:24:51,729] Trial 1 finished with value: 0.834920634920635 and parameters: {'hidden_layer_sizes ': 417, 'max_iter': 693}. Best is trial 1 with value: 0.834920634920635.\n",
      "[I 2024-10-31 20:24:52,448] Trial 2 finished with value: 0.834920634920635 and parameters: {'hidden_layer_sizes ': 850, 'max_iter': 351}. Best is trial 1 with value: 0.834920634920635.\n",
      "C:\\Users\\dan4i\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (258) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-10-31 20:24:52,773] Trial 3 finished with value: 0.7031746031746031 and parameters: {'hidden_layer_sizes ': 452, 'max_iter': 258}. Best is trial 1 with value: 0.834920634920635.\n",
      "C:\\Users\\dan4i\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (152) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-10-31 20:24:53,164] Trial 4 finished with value: 0.7031746031746031 and parameters: {'hidden_layer_sizes ': 933, 'max_iter': 152}. Best is trial 1 with value: 0.834920634920635.\n",
      "[I 2024-10-31 20:24:54,208] Trial 5 finished with value: 0.8126984126984127 and parameters: {'hidden_layer_sizes ': 803, 'max_iter': 946}. Best is trial 1 with value: 0.834920634920635.\n",
      "C:\\Users\\dan4i\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (127) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-10-31 20:24:54,510] Trial 6 finished with value: 0.680952380952381 and parameters: {'hidden_layer_sizes ': 794, 'max_iter': 127}. Best is trial 1 with value: 0.834920634920635.\n",
      "[I 2024-10-31 20:24:55,365] Trial 7 finished with value: 0.7904761904761906 and parameters: {'hidden_layer_sizes ': 750, 'max_iter': 479}. Best is trial 1 with value: 0.834920634920635.\n",
      "[I 2024-10-31 20:24:55,759] Trial 8 finished with value: 0.7031746031746031 and parameters: {'hidden_layer_sizes ': 191, 'max_iter': 740}. Best is trial 1 with value: 0.834920634920635.\n",
      "C:\\Users\\dan4i\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (309) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-10-31 20:24:56,153] Trial 9 finished with value: 0.834920634920635 and parameters: {'hidden_layer_sizes ': 455, 'max_iter': 309}. Best is trial 1 with value: 0.834920634920635.\n",
      "C:\\Users\\dan4i\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (679) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-10-31 20:24:56,404] Trial 10 finished with value: 0.680952380952381 and parameters: {'hidden_layer_sizes ': 25, 'max_iter': 679}. Best is trial 1 with value: 0.834920634920635.\n",
      "[I 2024-10-31 20:24:56,845] Trial 11 finished with value: 0.846031746031746 and parameters: {'hidden_layer_sizes ': 562, 'max_iter': 470}. Best is trial 11 with value: 0.846031746031746.\n",
      "[I 2024-10-31 20:24:57,489] Trial 12 finished with value: 0.8015873015873016 and parameters: {'hidden_layer_sizes ': 594, 'max_iter': 600}. Best is trial 11 with value: 0.846031746031746.\n",
      "[I 2024-10-31 20:24:57,581] Trial 13 finished with value: 0.6428571428571428 and parameters: {'hidden_layer_sizes ': 303, 'max_iter': 811}. Best is trial 11 with value: 0.846031746031746.\n",
      "[I 2024-10-31 20:24:58,371] Trial 14 finished with value: 0.7746031746031745 and parameters: {'hidden_layer_sizes ': 585, 'max_iter': 505}. Best is trial 11 with value: 0.846031746031746.\n",
      "[I 2024-10-31 20:24:58,748] Trial 15 finished with value: 0.7523809523809523 and parameters: {'hidden_layer_sizes ': 335, 'max_iter': 427}. Best is trial 11 with value: 0.846031746031746.\n",
      "[I 2024-10-31 20:24:59,442] Trial 16 finished with value: 0.7523809523809523 and parameters: {'hidden_layer_sizes ': 601, 'max_iter': 880}. Best is trial 11 with value: 0.846031746031746.\n",
      "[I 2024-10-31 20:24:59,697] Trial 17 finished with value: 0.7523809523809523 and parameters: {'hidden_layer_sizes ': 263, 'max_iter': 628}. Best is trial 11 with value: 0.846031746031746.\n",
      "[I 2024-10-31 20:24:59,888] Trial 18 finished with value: 0.7301587301587301 and parameters: {'hidden_layer_sizes ': 94, 'max_iter': 741}. Best is trial 11 with value: 0.846031746031746.\n",
      "C:\\Users\\dan4i\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (537) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-10-31 20:25:00,878] Trial 19 finished with value: 0.8238095238095238 and parameters: {'hidden_layer_sizes ': 669, 'max_iter': 537}. Best is trial 11 with value: 0.846031746031746.\n",
      "[I 2024-10-31 20:25:01,354] Trial 20 finished with value: 0.834920634920635 and parameters: {'hidden_layer_sizes ': 400, 'max_iter': 997}. Best is trial 11 with value: 0.846031746031746.\n",
      "C:\\Users\\dan4i\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (385) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-10-31 20:25:02,351] Trial 21 finished with value: 0.8238095238095238 and parameters: {'hidden_layer_sizes ': 951, 'max_iter': 385}. Best is trial 11 with value: 0.846031746031746.\n",
      "C:\\Users\\dan4i\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (334) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-10-31 20:25:02,832] Trial 22 finished with value: 0.8238095238095238 and parameters: {'hidden_layer_sizes ': 523, 'max_iter': 334}. Best is trial 11 with value: 0.846031746031746.\n",
      "C:\\Users\\dan4i\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (246) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-10-31 20:25:03,383] Trial 23 finished with value: 0.680952380952381 and parameters: {'hidden_layer_sizes ': 872, 'max_iter': 246}. Best is trial 11 with value: 0.846031746031746.\n",
      "C:\\Users\\dan4i\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (417) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[I 2024-10-31 20:25:04,122] Trial 24 finished with value: 0.8238095238095238 and parameters: {'hidden_layer_sizes ': 668, 'max_iter': 417}. Best is trial 11 with value: 0.846031746031746.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC-AUC for MLPClassifier:  0.846031746031746\n",
      "Best hyperparameters for MLPClassifier:  {'hidden_layer_sizes ': 562, 'max_iter': 470}\n"
     ]
    }
   ],
   "source": [
    "#оптимизируем гиперпараметры\n",
    "import optuna\n",
    "\n",
    "\n",
    "def objective_gbc(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 1, 200)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 10.0, log=True)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 500)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 200)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 100)\n",
    "\n",
    "    model = GradientBoostingClassifier(max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   n_estimators = n_estimators,\n",
    "                                    learning_rate = learning_rate)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "def objective_mlp(trial):\n",
    "    hidden_layer_sizes = trial.suggest_int('hidden_layer_sizes ', 2, 1000)\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000)\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        max_iter=max_iter\n",
    "    )\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "study_gbc = optuna.create_study(direction='maximize')\n",
    "study_gbc.optimize(objective_gbc, n_trials=50)\n",
    "\n",
    "print(\"Best ROC-AUC for GradientBoostingClassifier: \", study_gbc.best_value)\n",
    "print(\"Best hyperparameters for GradientBoostingClassifier: \", study_gbc.best_params)\n",
    "\n",
    "\n",
    "study_mlp = optuna.create_study(direction='maximize')\n",
    "study_mlp.optimize(objective_mlp, n_trials=25)\n",
    "\n",
    "print(\"Best ROC-AUC for MLPClassifier: \", study_mlp.best_value)\n",
    "print(\"Best hyperparameters for MLPClassifier: \", study_mlp.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "yJBK7MFr_xJx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yJBK7MFr_xJx",
    "outputId": "3a9d11b0-5ffd-449f-9975-3b18d5476a3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-31 20:27:22,629] A new study created in memory with name: no-name-f855cf28-cc3f-458e-86f4-4304c1e1c35d\n",
      "[I 2024-10-31 20:27:22,706] Trial 0 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 79, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.7031746031746031.\n",
      "[I 2024-10-31 20:27:22,812] Trial 1 finished with value: 0.7634920634920634 and parameters: {'n_estimators': 133, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.7634920634920634.\n",
      "[I 2024-10-31 20:27:22,887] Trial 2 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 91, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:22,977] Trial 3 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 118, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:23,067] Trial 4 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 113, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:23,155] Trial 5 finished with value: 0.6428571428571428 and parameters: {'n_estimators': 117, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:23,273] Trial 6 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 150, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:23,360] Trial 7 finished with value: 0.7634920634920634 and parameters: {'n_estimators': 109, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:23,464] Trial 8 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 136, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:23,561] Trial 9 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 128, 'max_depth': 17, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:23,718] Trial 10 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 200, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:23,770] Trial 11 finished with value: 0.5 and parameters: {'n_estimators': 54, 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:23,847] Trial 12 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 85, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:23,986] Trial 13 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 169, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:24,066] Trial 14 finished with value: 0.6428571428571428 and parameters: {'n_estimators': 88, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:24,134] Trial 15 finished with value: 0.692063492063492 and parameters: {'n_estimators': 66, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:24,226] Trial 16 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:24,360] Trial 17 finished with value: 0.6428571428571428 and parameters: {'n_estimators': 164, 'max_depth': 4, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:24,443] Trial 18 finished with value: 0.6428571428571428 and parameters: {'n_estimators': 93, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:24,509] Trial 19 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 69, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:24,633] Trial 20 finished with value: 0.6317460317460317 and parameters: {'n_estimators': 149, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:24,733] Trial 21 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 107, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:24,839] Trial 22 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 118, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:24,930] Trial 23 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 103, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:25,034] Trial 24 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 119, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:25,158] Trial 25 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 143, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:25,237] Trial 26 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 77, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:25,322] Trial 27 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 92, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.7746031746031745.\n",
      "[I 2024-10-31 20:27:25,419] Trial 28 finished with value: 0.7857142857142857 and parameters: {'n_estimators': 112, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:25,492] Trial 29 finished with value: 0.6317460317460317 and parameters: {'n_estimators': 74, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:25,580] Trial 30 finished with value: 0.6428571428571428 and parameters: {'n_estimators': 101, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:25,680] Trial 31 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 114, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:25,788] Trial 32 finished with value: 0.7031746031746031 and parameters: {'n_estimators': 125, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:25,904] Trial 33 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 135, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:26,011] Trial 34 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 124, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:26,106] Trial 35 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 108, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:26,195] Trial 36 finished with value: 0.6317460317460317 and parameters: {'n_estimators': 98, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:26,296] Trial 37 finished with value: 0.6428571428571428 and parameters: {'n_estimators': 112, 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:26,375] Trial 38 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 83, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:26,512] Trial 39 finished with value: 0.7634920634920634 and parameters: {'n_estimators': 161, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:26,574] Trial 40 finished with value: 0.5 and parameters: {'n_estimators': 61, 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:26,693] Trial 41 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 136, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:26,804] Trial 42 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 129, 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:26,928] Trial 43 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 144, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:27,106] Trial 44 finished with value: 0.6428571428571428 and parameters: {'n_estimators': 194, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:27,237] Trial 45 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 122, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:27,359] Trial 46 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 138, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:27,484] Trial 47 finished with value: 0.5714285714285714 and parameters: {'n_estimators': 154, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:27,631] Trial 48 finished with value: 0.6317460317460317 and parameters: {'n_estimators': 178, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 28 with value: 0.7857142857142857.\n",
      "[I 2024-10-31 20:27:27,741] Trial 49 finished with value: 0.7746031746031745 and parameters: {'n_estimators': 94, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 28 with value: 0.7857142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC-AUC for RandomForestClassifier:  0.7857142857142857\n",
      "Best hyperparameters for RandomForestClassifier:  {'n_estimators': 112, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 4}\n"
     ]
    }
   ],
   "source": [
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 20)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 5)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    return roc_auc\n",
    "\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(objective_rf, n_trials=50)\n",
    "\n",
    "print(\"Best ROC-AUC for RandomForestClassifier: \", study_rf.best_value)\n",
    "print(\"Best hyperparameters for RandomForestClassifier: \", study_rf.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "vJhgYJMPghrr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJhgYJMPghrr",
    "outputId": "0e4614c3-f62d-4ad1-9152-eda9d5ddd0ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest метрики:\n",
      "ROC AUC: 0.79\n",
      "Accuracy: 0.94\n",
      "Precision: 0.94\n",
      "Recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Обучение Random Forest\n",
    "rf_params = {'n_estimators': 121, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 3}\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Прогноз на тестовых данных\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Расчет метрик для Random Forest\n",
    "rf_roc_auc = roc_auc_score(y_test, rf_pred)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_precision = precision_score(y_test, rf_pred)\n",
    "rf_recall = recall_score(y_test, rf_pred)\n",
    "\n",
    "print(\"Random Forest метрики:\")\n",
    "print(f\"ROC AUC: {rf_roc_auc:.2f}\")\n",
    "print(f\"Accuracy: {rf_accuracy:.2f}\")\n",
    "print(f\"Precision: {rf_precision:.2f}\")\n",
    "print(f\"Recall: {rf_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Wl09RCJZ_SRb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wl09RCJZ_SRb",
    "outputId": "8c1e9091-65d2-42b7-db4c-1de2235cbfff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting метрики:\n",
      "ROC AUC: 0.81\n",
      "Accuracy: 0.88\n",
      "Precision: 0.95\n",
      "Recall: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Обучение Gradient Boosting\n",
    "gb_params = {'n_estimators': 112, 'learning_rate': 0.12048539180625001, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5, 'subsample': 0.8020632465655403, 'max_features': 'log2'}\n",
    "gb_model = GradientBoostingClassifier(**gb_params)\n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Прогноз на тестовых данных\n",
    "gb_pred = gb_model.predict(X_test_scaled)\n",
    "\n",
    "# Расчет метрик для Gradient Boosting\n",
    "gb_roc_auc = roc_auc_score(y_test, gb_pred)\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "gb_precision = precision_score(y_test, gb_pred)\n",
    "gb_recall = recall_score(y_test, gb_pred)\n",
    "\n",
    "print(\"\\nGradient Boosting метрики:\")\n",
    "print(f\"ROC AUC: {gb_roc_auc:.2f}\")\n",
    "print(f\"Accuracy: {gb_accuracy:.2f}\")\n",
    "print(f\"Precision: {gb_precision:.2f}\")\n",
    "print(f\"Recall: {gb_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae1e040c-ddd0-4952-9dcb-58c1226da40a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae1e040c-ddd0-4952-9dcb-58c1226da40a",
    "outputId": "d461e90d-e99a-43eb-e4b3-dc2e697b9933",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP (Neural Network) метрики:\n",
      "ROC AUC: 0.91\n",
      "Accuracy: 0.94\n",
      "Precision: 0.98\n",
      "Recall: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Обучение MLP (Multi-Layer Perceptron) нейронной сети\n",
    "mlp_params = {'hidden_layer_sizes': 366, 'max_iter': 626}\n",
    "mlp_model = MLPClassifier(**mlp_params)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Прогноз на тестовых данных\n",
    "mlp_pred = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Расчет метрик для MLP нейронной сети\n",
    "mlp_roc_auc = roc_auc_score(y_test, mlp_pred)\n",
    "mlp_accuracy = accuracy_score(y_test, mlp_pred)\n",
    "mlp_precision = precision_score(y_test, mlp_pred)\n",
    "mlp_recall = recall_score(y_test, mlp_pred)\n",
    "\n",
    "print(\"\\nMLP (Neural Network) метрики:\")\n",
    "print(f\"ROC AUC: {mlp_roc_auc:.2f}\")\n",
    "print(f\"Accuracy: {mlp_accuracy:.2f}\")\n",
    "print(f\"Precision: {mlp_precision:.2f}\")\n",
    "print(f\"Recall: {mlp_recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6eb00-77fd-40dc-a3c5-35c1fe0200c0",
   "metadata": {
    "id": "d2d6eb00-77fd-40dc-a3c5-35c1fe0200c0"
   },
   "source": [
    "## Экспериментируйте\n",
    "Для получения лучшего качества придется поэкспериментировать. Подсказка: попробуйте оптимизировать гиперпараметры модели"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
